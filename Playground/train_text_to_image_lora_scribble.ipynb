{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mh3XZfyaWmgi"
   },
   "source": [
    "# The notebook for training the text to image model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gkqbPaQWmgl"
   },
   "source": [
    "## Package Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nO00CrUCWmgm"
   },
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30051,
     "status": "ok",
     "timestamp": 1683017219191,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "93wvvwmiW09_",
    "outputId": "bf190fa2-d009-4319-d07e-f476703b1865"
   },
   "outputs": [],
   "source": [
    "# !pip install -q datasets\n",
    "# !pip install -q transformers\n",
    "# !pip install -q accelerate\n",
    "# !pip install -q git+https://github.com/huggingface/diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 19250,
     "status": "ok",
     "timestamp": 1683017238437,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "e1focegPWmgm"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint\n",
    "import transformers\n",
    "from accelerate import Accelerator\n",
    "from accelerate.logging import get_logger\n",
    "from accelerate.utils import ProjectConfiguration, set_seed\n",
    "from datasets import load_dataset, Dataset\n",
    "from huggingface_hub import create_repo, upload_folder\n",
    "from packaging import version\n",
    "from torchvision import transforms\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "\n",
    "import diffusers\n",
    "from diffusers import AutoencoderKL, DDPMScheduler, DiffusionPipeline, UNet2DConditionModel\n",
    "from diffusers.loaders import AttnProcsLayers\n",
    "from diffusers.models.attention_processor import LoRAAttnProcessor\n",
    "from diffusers.optimization import get_scheduler\n",
    "from diffusers.utils import check_min_version, is_wandb_available\n",
    "from diffusers.utils.import_utils import is_xformers_available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VU4_-zreWmgo"
   },
   "source": [
    "### Check diffuser version & Save model card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1683017238438,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "z9QW17qjWmgo"
   },
   "outputs": [],
   "source": [
    "check_min_version(\"0.16.0.dev0\")\n",
    "\n",
    "logger = get_logger(__name__, log_level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1683017238438,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "is0Sk5UgWmgo"
   },
   "outputs": [],
   "source": [
    "def save_model_card(repo_id: str, images=None, base_model=str, dataset_name=str, repo_folder=None):\n",
    "    img_str = \"\"\n",
    "    for i, image in enumerate(images):\n",
    "        image.save(os.path.join(repo_folder, f\"image_{i}.png\"))\n",
    "        img_str += f\"![img_{i}](./image_{i}.png)\\n\"\n",
    "\n",
    "    yaml = f\"\"\"\n",
    "---\n",
    "license: creativeml-openrail-m\n",
    "base_model: {base_model}\n",
    "tags:\n",
    "- stable-diffusion\n",
    "- stable-diffusion-diffusers\n",
    "- text-to-image\n",
    "- diffusers\n",
    "- lora\n",
    "inference: true\n",
    "---\n",
    "    \"\"\"\n",
    "    model_card = f\"\"\"\n",
    "# LoRA text2image fine-tuning - {repo_id}\n",
    "These are LoRA adaption weights for {base_model}. The weights were fine-tuned on the {dataset_name} dataset. You can find some example images in the following. \\n\n",
    "{img_str}\n",
    "\"\"\"\n",
    "    with open(os.path.join(repo_folder, \"README.md\"), \"w\") as f:\n",
    "        f.write(yaml + model_card)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZgHaY-6HrcX"
   },
   "source": [
    "## Set Basic Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qI2U5vMUCQpU"
   },
   "source": [
    "### Saving Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1683017238438,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "Ha5_2C77HVH6",
    "outputId": "9bfb3db7-dcd4-437f-ea9b-aa46bc2cbbe8"
   },
   "outputs": [],
   "source": [
    "#@markdown If model weights should be saved directly in google drive (takes around 4-5 GB).\n",
    "save_to_gdrive = False #@param {type:\"boolean\"}\n",
    "if save_to_gdrive:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "#@markdown Name/Path of the initial model.\n",
    "pretrained_model_name_or_path = \"runwayml/stable-diffusion-v1-5\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown Enter the directory name to save model at.\n",
    "\n",
    "# output_dir = \"ml_stable_diffusion_weights/lora\" #@param {type:\"string\"}\n",
    "# if save_to_gdrive:\n",
    "#     output_dir = \"/content/drive/MyDrive/\" + output_dir\n",
    "# else:\n",
    "#     output_dir = \"/content/\" + output_dir\n",
    "\n",
    "# print(f\"[*] Weights will be saved at {output_dir}\")\n",
    "\n",
    "# !mkdir -p $output_dir\n",
    "output_dir = \"lora_output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_62vWMtSCT4u"
   },
   "source": [
    "### Configure Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1683017238439,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "xVaFFSzYJTWj",
    "outputId": "a3066d4e-ddce-430f-c635-c77e085187ef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yg2709/.local/lib/python3.10/site-packages/accelerate/accelerator.py:249: FutureWarning: `logging_dir` is deprecated and will be removed in version 0.18.0 of ðŸ¤— Accelerate. Use `project_dir` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "logging_dir = os.path.join(output_dir, \"logs\")\n",
    "accelerator_project_config = ProjectConfiguration(total_limit=None)\n",
    "\n",
    "accelerator = Accelerator(\n",
    "        gradient_accumulation_steps=1,\n",
    "        mixed_precision=\"fp16\",\n",
    "        log_with=\"tensorboard\",\n",
    "        logging_dir=logging_dir,\n",
    "        project_config=accelerator_project_config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSo71ENuCpdp"
   },
   "source": [
    "### Handle Repository Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1683017238439,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "wQ315Se2H2W9"
   },
   "outputs": [],
   "source": [
    "if accelerator.is_main_process:\n",
    "        if output_dir is not None:\n",
    "            os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pa6ha1NMCu9R"
   },
   "source": [
    "### Load scheduler, tokenizer, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26870,
     "status": "ok",
     "timestamp": 1683017265292,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "SEDGy98GCul5",
    "outputId": "8a932d99-0411-4dc8-af01-af0e3548cf6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIPTextModel(\n",
       "  (text_model): CLIPTextTransformer(\n",
       "    (embeddings): CLIPTextEmbeddings(\n",
       "      (token_embedding): Embedding(49408, 768)\n",
       "      (position_embedding): Embedding(77, 768)\n",
       "    )\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_scheduler = DDPMScheduler.from_pretrained(pretrained_model_name_or_path, subfolder=\"scheduler\")\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path, subfolder=\"tokenizer\", revision=None\n",
    ")\n",
    "text_encoder = CLIPTextModel.from_pretrained(\n",
    "    pretrained_model_name_or_path, subfolder=\"text_encoder\", revision=None\n",
    ")\n",
    "vae = AutoencoderKL.from_pretrained(pretrained_model_name_or_path, subfolder=\"vae\", revision=None)\n",
    "unet = UNet2DConditionModel.from_pretrained(\n",
    "    pretrained_model_name_or_path, subfolder=\"unet\", revision=None\n",
    ")\n",
    "# freeze parameters of models to save more memory\n",
    "unet.requires_grad_(False)\n",
    "vae.requires_grad_(False)\n",
    "\n",
    "text_encoder.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1683017265293,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "g2Pud9ivDFWN"
   },
   "outputs": [],
   "source": [
    "weight_dtype = torch.float32\n",
    "if accelerator.mixed_precision == \"fp16\":\n",
    "    weight_dtype = torch.float16\n",
    "elif accelerator.mixed_precision == \"bf16\":\n",
    "    weight_dtype = torch.bfloat16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ot_Sq9v0O_V7"
   },
   "source": [
    "### Move unet, vae, text_encoder to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1683017265293,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "O9XL4FxOPH4h",
    "outputId": "25b1499b-31f5-472f-8e84-d76764678a77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(accelerator.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10709,
     "status": "ok",
     "timestamp": 1683017275984,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "G_Rxo6ToPFbh",
    "outputId": "eec77fa2-39f8-4338-a6aa-353308638509"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIPTextModel(\n",
       "  (text_model): CLIPTextTransformer(\n",
       "    (embeddings): CLIPTextEmbeddings(\n",
       "      (token_embedding): Embedding(49408, 768)\n",
       "      (position_embedding): Embedding(77, 768)\n",
       "    )\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet.to(accelerator.device, dtype=weight_dtype)\n",
    "vae.to(accelerator.device, dtype=weight_dtype)\n",
    "text_encoder.to(accelerator.device, dtype=weight_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U8h9lgIcQmh8"
   },
   "source": [
    "## Start adding LoRA weights to attention layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_KfZQ9NQ3cQ"
   },
   "source": [
    "    # It's important to realize here how many attention weights will be added and of which sizes\n",
    "    # The sizes of the attention layers consist only of two different variables:\n",
    "    # 1) - the \"hidden_size\", which is increased according to `unet.config.block_out_channels`.\n",
    "    # 2) - the \"cross attention size\", which is set to `unet.config.cross_attention_dim`.\n",
    "\n",
    "    # Let's first see how many attention processors we will have to set.\n",
    "    # For Stable Diffusion, it should be equal to:\n",
    "    # - down blocks (2x attention layers) * (2x transformer layers) * (3x down blocks) = 12\n",
    "    # - mid blocks (2x attention layers) * (1x transformer layers) * (1x mid blocks) = 2\n",
    "    # - up blocks (2x attention layers) * (3x transformer layers) * (3x down blocks) = 18\n",
    "    # => 32 layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cojUnRQ8SKpe"
   },
   "source": [
    "### Set correct lora layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1683017275985,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "LRiotiE3QqFA"
   },
   "outputs": [],
   "source": [
    "lora_attn_procs = {}\n",
    "for name in unet.attn_processors.keys():\n",
    "  cross_attention_dim = None if name.endswith(\"attn1.processor\") else unet.config.cross_attention_dim\n",
    "  # print(name)\n",
    "  if name.startswith(\"mid_block\"):\n",
    "    # print(unet.config.block_out_channels)\n",
    "    hidden_size = unet.config.block_out_channels[-1]\n",
    "  elif name.startswith(\"up_blocks\"):\n",
    "    block_id = int(name[len(\"up_blocks.\")])\n",
    "    hidden_size = list(reversed(unet.config.block_out_channels))[block_id]\n",
    "    # print(hidden_size)\n",
    "  elif name.startswith(\"down_blocks\"):\n",
    "    block_id = int(name[len(\"down_blocks.\")])\n",
    "    hidden_size = unet.config.block_out_channels[block_id]\n",
    "    # print(hidden_size)\n",
    "\n",
    "  lora_attn_procs[name] = LoRAAttnProcessor(hidden_size=hidden_size, cross_attention_dim=cross_attention_dim)\n",
    "\n",
    "unet.set_attn_processor(lora_attn_procs)\n",
    "lora_layers = AttnProcsLayers(unet.attn_processors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vd_fnwGreN5e"
   },
   "source": [
    "### Initalize optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1683017275985,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "o2iDK19WeRC1"
   },
   "outputs": [],
   "source": [
    "#@markdown Parameters for adamW\n",
    "\n",
    "optimizer_cls = torch.optim.AdamW\n",
    "learning_rate = 1e-4 #@param {type:\"number\"}\n",
    "adam_beta1 = 0.9 #@param {type:\"number\"}\n",
    "adam_beta2 = 0.999 #@param {type:\"number\"}\n",
    "adam_weight_decay = 1e-2 #@param {type:\"number\"}\n",
    "adam_epsilon = 1e-08 #@param {type:\"number\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1683017275985,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "ksbDWPUue_6U"
   },
   "outputs": [],
   "source": [
    "optimizer = optimizer_cls(\n",
    "    lora_layers.parameters(),\n",
    "    lr=learning_rate,\n",
    "    betas=(adam_beta1,adam_beta2),\n",
    "    weight_decay=adam_weight_decay,\n",
    "    eps=adam_epsilon,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1w4gQxqg_9X"
   },
   "source": [
    "### Load Quickdraw Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eV-n3sHokHc2"
   },
   "source": [
    "#### Read the class name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1683017275985,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "wU_5ICsPkNLy",
    "outputId": "32d60914-d1c5-43ee-a150-cde689df8779"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-05-02 06:49:20--  https://raw.githubusercontent.com/zaidalyafeai/zaidalyafeai.github.io/master/sketcher/mini_classes.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 760 [text/plain]\n",
      "Saving to: 'mini_classes.txt.1'\n",
      "\n",
      "mini_classes.txt.1  100%[===================>]     760  --.-KB/s    in 0s      \n",
      "\n",
      "2023-05-02 06:49:20 (50.1 MB/s) - 'mini_classes.txt.1' saved [760/760]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !wget 'https://raw.githubusercontent.com/zaidalyafeai/zaidalyafeai.github.io/master/sketcher/mini_classes.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1683017275985,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "8uv2g78AkPeq"
   },
   "outputs": [],
   "source": [
    "f = open(\"mini_classes.txt\",\"r\")\n",
    "# And for reading use\n",
    "classes = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1683017275985,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "zRRtMu-ckShz",
    "outputId": "8045572b-03b7-4f44-beac-aac53f13462c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "classes = [c.replace('\\n','').replace(' ','_') for c in classes]\n",
    "print(len(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZtE2CL1kYly"
   },
   "source": [
    "Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1683017275986,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "2J8gGg_-kmmI",
    "outputId": "ee750384-c1fb-4593-ad2c-f74372af1b1a"
   },
   "outputs": [],
   "source": [
    "# !mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 1275,
     "status": "ok",
     "timestamp": 1683017277256,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "hG1l0eHnkUST"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from tqdm.auto import tqdm\n",
    "def download():\n",
    "    base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
    "    for c in tqdm(classes):        \n",
    "        cls_url = c.replace('_', '%20')\n",
    "        path = base+cls_url+'.npy'\n",
    "        # print(path)\n",
    "        urllib.request.urlretrieve(path, 'data/'+c+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "0dd42580052d4f8a90071707db1499cf",
      "63e581c6e0c343be825fba234a14948a",
      "d6dae65589af4dc39de7975a10d777bc",
      "0cde353828f745f0a6b58a703397322d",
      "5185fa6f5b654bd2901f24b139e1ccde",
      "08dbb8f6f3f94f1586497ee625f8a633",
      "321b33e8f6444f869f4b6fa571a5278c",
      "e98cc65d8c9d463ea456675cfbfa46f9",
      "5ad8cc752f3442d7a62aefe2ca79a299",
      "7890f7bc590f4748bacf54530c796204",
      "eb4ba770895a4eb2b26912129aa86cef"
     ]
    },
    "executionInfo": {
     "elapsed": 337338,
     "status": "ok",
     "timestamp": 1683017614586,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "nc4W_zSblknV",
    "outputId": "0033b55a-c67b-4401-83d0-47fc89310ff2"
   },
   "outputs": [],
   "source": [
    "# download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIc6y0ZwhpmH"
   },
   "source": [
    "load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1683017614587,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "uwzcUqnthv1c"
   },
   "outputs": [],
   "source": [
    "# def load_data(root, vfold_ratio=0.2, max_items_per_class= 4000 ):\n",
    "#     all_files = glob.glob(os.path.join(root, '*.npy'))\n",
    "\n",
    "#     #initialize variables \n",
    "#     x = np.empty([0, 784])\n",
    "#     y = np.empty([0])\n",
    "#     class_names = []\n",
    "\n",
    "#     #load each data file \n",
    "#     for idx, file in enumerate(all_files):\n",
    "#         data = np.load(file)\n",
    "#         data = data[0: max_items_per_class, :]\n",
    "#         labels = np.full(data.shape[0], idx)\n",
    "\n",
    "#         x = np.concatenate((x, data), axis=0)\n",
    "#         y = np.append(y, labels)\n",
    "\n",
    "#         class_name, ext = os.path.splitext(os.path.basename(file))\n",
    "#         class_names.append(class_name)\n",
    "\n",
    "#     data = None\n",
    "#     labels = None\n",
    "    \n",
    "#     #randomize the dataset \n",
    "#     permutation = np.random.permutation(y.shape[0])\n",
    "#     x = x[permutation, :]\n",
    "#     y = y[permutation]\n",
    "\n",
    "#     #separate into training and testing \n",
    "#     vfold_size = int(x.shape[0]/100*(vfold_ratio*100))\n",
    "\n",
    "#     x_test = x[0:vfold_size, :]\n",
    "#     y_test = y[0:vfold_size]\n",
    "\n",
    "#     x_train = x[vfold_size:x.shape[0], :]\n",
    "#     y_train = y[vfold_size:y.shape[0]]\n",
    "#     return x_train, y_train, x_test, y_test, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1683017614587,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "rTIFQgpEh0LM"
   },
   "outputs": [],
   "source": [
    "# x_train, y_train, x_test, y_test, class_names = load_data('data')\n",
    "# num_classes = len(class_names)\n",
    "# image_size = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1683017614587,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "wMC2NoKMh1tf"
   },
   "outputs": [],
   "source": [
    "# print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1683017614587,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "uiXQNmxNh-Q8"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from random import randint\n",
    "# %matplotlib inline  \n",
    "# idx = randint(0, len(x_train))\n",
    "# plt.imshow(x_train[idx].reshape(28,28)) \n",
    "# print(class_names[int(y_train[idx].item())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1683017614588,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "VmTPTkzYqKm6"
   },
   "outputs": [],
   "source": [
    "# print(len(classes))\n",
    "# print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1683017614588,
     "user": {
      "displayName": "Yuanhe Guo",
      "userId": "15375666072009626681"
     },
     "user_tz": -480
    },
    "id": "azQediYhFLPv"
   },
   "outputs": [],
   "source": [
    "def load_data_for_diffusion(root, max_items_per_class= 4000 ):\n",
    "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
    "\n",
    "    #initialize variables\n",
    "    imgs = np.empty([0, 784])\n",
    "    labels = []\n",
    "\n",
    "    for idx, file in enumerate(all_files):\n",
    "      data = np.load(file)\n",
    "      data = data[0: max_items_per_class, :]\n",
    "\n",
    "      class_name, ext = os.path.splitext(os.path.basename(file))\n",
    "      labels.extend([\"a scribble of\" + class_name for i in range(data.shape[0])])\n",
    "\n",
    "      imgs = np.concatenate((imgs, data), axis=0)\n",
    "\n",
    "\n",
    "    return imgs, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ofg_cU0fI-78",
    "outputId": "e32735b3-0364-48eb-cf87-98129f564f20"
   },
   "outputs": [],
   "source": [
    "imgs, labels = load_data_for_diffusion('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 784)\n",
      "400000\n"
     ]
    }
   ],
   "source": [
    "print(imgs.shape)\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a scribble oflollipop</th>\n",
       "      <th>a scribble oflollipop</th>\n",
       "      <th>a scribble oflollipop</th>\n",
       "      <th>a scribble oflollipop</th>\n",
       "      <th>a scribble oflollipop</th>\n",
       "      <th>a scribble oflollipop</th>\n",
       "      <th>a scribble oflollipop</th>\n",
       "      <th>a scribble oflollipop</th>\n",
       "      <th>a scribble oflollipop</th>\n",
       "      <th>a scribble oflollipop</th>\n",
       "      <th>...</th>\n",
       "      <th>a scribble ofbeard</th>\n",
       "      <th>a scribble ofbeard</th>\n",
       "      <th>a scribble ofbeard</th>\n",
       "      <th>a scribble ofbeard</th>\n",
       "      <th>a scribble ofbeard</th>\n",
       "      <th>a scribble ofbeard</th>\n",
       "      <th>a scribble ofbeard</th>\n",
       "      <th>a scribble ofbeard</th>\n",
       "      <th>a scribble ofbeard</th>\n",
       "      <th>a scribble ofbeard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>784 rows Ã— 400000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     a scribble oflollipop  a scribble oflollipop  a scribble oflollipop   \n",
       "0                      0.0                    0.0                    0.0  \\\n",
       "1                      0.0                    0.0                    0.0   \n",
       "2                      0.0                    0.0                    0.0   \n",
       "3                      0.0                    0.0                    0.0   \n",
       "4                      0.0                    0.0                    0.0   \n",
       "..                     ...                    ...                    ...   \n",
       "779                    0.0                    0.0                    0.0   \n",
       "780                    0.0                    0.0                    0.0   \n",
       "781                    0.0                    0.0                    0.0   \n",
       "782                    0.0                    0.0                    0.0   \n",
       "783                    0.0                    0.0                    0.0   \n",
       "\n",
       "     a scribble oflollipop  a scribble oflollipop  a scribble oflollipop   \n",
       "0                      0.0                    0.0                    0.0  \\\n",
       "1                      0.0                    0.0                    0.0   \n",
       "2                      0.0                    0.0                    0.0   \n",
       "3                      0.0                    0.0                    0.0   \n",
       "4                      0.0                    0.0                    0.0   \n",
       "..                     ...                    ...                    ...   \n",
       "779                    0.0                    0.0                    0.0   \n",
       "780                    0.0                    0.0                    0.0   \n",
       "781                    0.0                    0.0                    0.0   \n",
       "782                    0.0                    0.0                    0.0   \n",
       "783                    0.0                    0.0                    0.0   \n",
       "\n",
       "     a scribble oflollipop  a scribble oflollipop  a scribble oflollipop   \n",
       "0                      0.0                    0.0                    0.0  \\\n",
       "1                      0.0                    0.0                    0.0   \n",
       "2                      0.0                    0.0                    0.0   \n",
       "3                      0.0                    0.0                    0.0   \n",
       "4                      0.0                    0.0                    0.0   \n",
       "..                     ...                    ...                    ...   \n",
       "779                    0.0                    0.0                    0.0   \n",
       "780                    0.0                    0.0                    0.0   \n",
       "781                    0.0                    0.0                    0.0   \n",
       "782                    0.0                    0.0                    0.0   \n",
       "783                    0.0                    0.0                    0.0   \n",
       "\n",
       "     a scribble oflollipop  ...  a scribble ofbeard  a scribble ofbeard   \n",
       "0                      0.0  ...                 0.0                 0.0  \\\n",
       "1                      0.0  ...                 0.0                 0.0   \n",
       "2                      0.0  ...                 0.0                 0.0   \n",
       "3                      0.0  ...                 0.0                 0.0   \n",
       "4                      0.0  ...                 0.0                 0.0   \n",
       "..                     ...  ...                 ...                 ...   \n",
       "779                    0.0  ...                 0.0                 0.0   \n",
       "780                    0.0  ...                 0.0                 0.0   \n",
       "781                    0.0  ...                 0.0                 0.0   \n",
       "782                    0.0  ...                 0.0                 0.0   \n",
       "783                    0.0  ...                 0.0                 0.0   \n",
       "\n",
       "     a scribble ofbeard  a scribble ofbeard  a scribble ofbeard   \n",
       "0                   0.0                 0.0                 0.0  \\\n",
       "1                   0.0                 0.0                 0.0   \n",
       "2                   0.0                 0.0                 0.0   \n",
       "3                   0.0                 0.0                 0.0   \n",
       "4                   0.0                 0.0                 0.0   \n",
       "..                  ...                 ...                 ...   \n",
       "779                 0.0                 0.0                 0.0   \n",
       "780                 0.0                 0.0                 0.0   \n",
       "781                 0.0                 0.0                 0.0   \n",
       "782                 0.0                 0.0                 0.0   \n",
       "783                 0.0                 0.0                 0.0   \n",
       "\n",
       "     a scribble ofbeard  a scribble ofbeard  a scribble ofbeard   \n",
       "0                   0.0                 0.0                 0.0  \\\n",
       "1                   0.0                 0.0                 0.0   \n",
       "2                   0.0                 0.0                 0.0   \n",
       "3                   0.0                 0.0                 0.0   \n",
       "4                   0.0                 0.0                 0.0   \n",
       "..                  ...                 ...                 ...   \n",
       "779                 0.0                 0.0                 0.0   \n",
       "780                 0.0                 0.0                 0.0   \n",
       "781                 0.0                 0.0                 0.0   \n",
       "782                 0.0                 0.0                 0.0   \n",
       "783                 0.0                 0.0                 0.0   \n",
       "\n",
       "     a scribble ofbeard  a scribble ofbeard  \n",
       "0                   0.0                 0.0  \n",
       "1                   0.0                 0.0  \n",
       "2                   0.0                 0.0  \n",
       "3                   0.0                 0.0  \n",
       "4                   0.0                 0.0  \n",
       "..                  ...                 ...  \n",
       "779                 0.0                 0.0  \n",
       "780                 0.0                 0.0  \n",
       "781                 0.0                 0.0  \n",
       "782                 0.0                 0.0  \n",
       "783                 0.0                 0.0  \n",
       "\n",
       "[784 rows x 400000 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_imgs = pd.DataFrame(imgs.T, columns=labels)\n",
    "labeled_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_captions(labels):\n",
    "    captions = []\n",
    "    for caption in labels:\n",
    "        if isinstance(caption, str):\n",
    "            captions.append(caption)\n",
    "        elif isinstance(caption, (list, np.ndarray)):\n",
    "            # take a random caption if there are multiple\n",
    "            captions.append(random.choice(caption) if is_train else caption[0])\n",
    "            \n",
    "    inputs = tokenizer(\n",
    "            captions, max_length=tokenizer.model_max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n",
    "        )\n",
    "    return inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[49406,   320,  2139,  ..., 49407, 49407, 49407],\n",
       "        [49406,   320,  2139,  ..., 49407, 49407, 49407],\n",
       "        [49406,   320,  2139,  ..., 49407, 49407, 49407],\n",
       "        ...,\n",
       "        [49406,   320,  2139,  ..., 49407, 49407, 49407],\n",
       "        [49406,   320,  2139,  ..., 49407, 49407, 49407],\n",
       "        [49406,   320,  2139,  ..., 49407, 49407, 49407]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenize_captions(labels=labels)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400000, 77])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "imgs_RGB = [Image.fromarray(img.reshape(28,28)).convert(\"RGB\") for img in imgs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_values = [train_transforms(img) for img in imgs_RGB]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoaders Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data_dic):\n",
    "    pixel_values = torch.stack([pixel for pixel in data_dic['pixel_values']])\n",
    "    pixel_values = pixel_values.to(memory_format=torch.contiguous_format).float()\n",
    "    input_ids = torch.stack([pixel for pixel in data_dic['input_ids']])\n",
    "    return {\"pixel_values\": pixel_values, \"input_ids\": input_ids}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size=16\n",
    "train_dataset_dic = {\"input_ids\": input_ids, \"pixel_values\": pixel_values}\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset_dic,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    batch_size=train_batch_size,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scheduler and math around the number of training steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_accumulation_steps = 1\n",
    "num_train_epochs = 100\n",
    "num_update_steps_per_epoch = math.ceil(len(train_dataloader) / gradient_accumulation_steps)\n",
    "max_train_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "lr_warmup_steps = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = \"constant\"\n",
    "lr_scheduler = get_scheduler(\n",
    "    lr_scheduler,\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=lr_warmup_steps * gradient_accumulation_steps,\n",
    "    num_training_steps=max_train_steps * gradient_accumulation_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare everything with accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_layers, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
    "        lora_layers, optimizer, train_dataloader, lr_scheduler\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recalculate our total training steps as the size of the training dataloader may have changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_update_steps_per_epoch = math.ceil(len(train_dataloader) / gradient_accumulation_steps)\n",
    "max_train_steps = num_train_epochs * num_update_steps_per_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_batch_size = train_batch_size * accelerator.num_processes * gradient_accumulation_steps\n",
    "\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(f\"  Num examples = {len(labels)}\")\n",
    "logger.info(f\"  Num Epochs = {num_train_epochs}\")\n",
    "logger.info(f\"  Instantaneous batch size per device = {train_batch_size}\")\n",
    "logger.info(f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\")\n",
    "logger.info(f\"  Gradient Accumulation steps = {gradient_accumulation_steps}\")\n",
    "logger.info(f\"  Total optimization steps = {max_train_steps}\")\n",
    "\n",
    "global_step = 0\n",
    "first_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6baf05fb66fa4ab1a9685b6e23f67221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progress_bar = tqdm(range(global_step, max_train_steps), disable=not accelerator.is_local_main_process)\n",
    "progress_bar.set_description(\"Steps\")\n",
    "\n",
    "checkpointing_steps = 500\n",
    "\n",
    "for epoch in range(first_epoch, num_train_epochs):\n",
    "    unet.train()\n",
    "    train_loss = 0.0\n",
    "    for step, batch in enumverate(train_dataloader):\n",
    "        with accelerator.accumulate(unet):\n",
    "            # convert images to latent space\n",
    "            latents = vae.encode(batch[\"pixel_values\"].to(dtype=weight_dtype)).latent_dist.sample()\n",
    "            latents = latents * vae.config.scaling_factor\n",
    "            \n",
    "            # sample noise that we'll add to the latents\n",
    "            noise = torch.randn_like(latents)\n",
    "            bsz = latents.shape[0]\n",
    "            \n",
    "            # Sample a random timestep for each image\n",
    "            timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (bsz,), device=latents.device)\n",
    "            timesteps = timesteps.long()\n",
    "            \n",
    "            # Add noise to the latents according to the noise magnitude at each timestep\n",
    "            # (this is the forward diffusion process)\n",
    "            noisy_latents = noise_scheduler.add_noise(latents, noise, timesteps)\n",
    "            \n",
    "            # Get the text embedding for conditioning\n",
    "            encoder_hidden_states = text_encoder(batch[\"input_ids\"])[0]\n",
    "            \n",
    "            # Get the target for loss depending on the prediction type\n",
    "            if noise_scheduler.config.prediction_type == \"epsilon\":\n",
    "                target = noise\n",
    "            elif noise_scheduler.config.prediction_type == \"v_prediction\":\n",
    "                target = noise_scheduler.get_velocity(latents, noise, timesteps)\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown prediction type {noise_scheduler.config.prediction_type}\")\n",
    "                \n",
    "            \n",
    "            # Predict the noise residual and compute loss\n",
    "            model_pred = unet(noisy_latents, timesteps, encoder_hidden_states).sample\n",
    "            loss = F.mse_loss(model_pred.float(), target.float(), reduction=\"mean\")\n",
    "            \n",
    "            # Gather the losses across all processes\n",
    "            avg_loss = accelerator.gather(loss.repeat(args.train_batch_size)).mean()\n",
    "            train_loss += avg_loss.item() / args.gradient_accumulation_steps\n",
    "            \n",
    "            # Backpropagate\n",
    "            accelerator.backward(loss)\n",
    "            if accelerator.sync_gradients:\n",
    "                params_to_clip = lora_layers.parameters()\n",
    "                accelerator.clip_grad_norm_(params_to_clip, args.max_grad_norm)\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # update procress bar\n",
    "            if accelerator.sync_gradients:\n",
    "                progress_bar.update(1)\n",
    "                global_step += 1\n",
    "                accelerator.log({\"train_loss\":  train_loss}, step=global_step)\n",
    "                train_loss = 0.0\n",
    "                \n",
    "                if global_step % checkpointing_steps == 0:\n",
    "                    if accelerator.is_main_process:\n",
    "                        save_path = os.path.join(output_dir, f\"checkpoint-{global_step}\")\n",
    "                        accelerator.save_state(save_path)\n",
    "                        logger.info(f\"Saved state to {save_path}\")\n",
    "                        \n",
    "            logs = {\"step_loss\": loss.detach().item(), \"lr\": lr_scheduler.get_last_lr()[0]}\n",
    "            progress_bar.set_postfix(**logs)\n",
    "            \n",
    "            if global_step >= args.max_train_steps:\n",
    "                break\n",
    "        \n",
    "        if accelerator.is_main_process:\n",
    "            validation_prompt = \"a scribble of horse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "ml_project_env",
   "language": "python",
   "name": "ml_project_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08dbb8f6f3f94f1586497ee625f8a633": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0cde353828f745f0a6b58a703397322d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7890f7bc590f4748bacf54530c796204",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_eb4ba770895a4eb2b26912129aa86cef",
      "value": " 100/100 [05:38&lt;00:00,  3.32s/it]"
     }
    },
    "0dd42580052d4f8a90071707db1499cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_63e581c6e0c343be825fba234a14948a",
       "IPY_MODEL_d6dae65589af4dc39de7975a10d777bc",
       "IPY_MODEL_0cde353828f745f0a6b58a703397322d"
      ],
      "layout": "IPY_MODEL_5185fa6f5b654bd2901f24b139e1ccde"
     }
    },
    "321b33e8f6444f869f4b6fa571a5278c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5185fa6f5b654bd2901f24b139e1ccde": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ad8cc752f3442d7a62aefe2ca79a299": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "63e581c6e0c343be825fba234a14948a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08dbb8f6f3f94f1586497ee625f8a633",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_321b33e8f6444f869f4b6fa571a5278c",
      "value": "100%"
     }
    },
    "7890f7bc590f4748bacf54530c796204": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6dae65589af4dc39de7975a10d777bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e98cc65d8c9d463ea456675cfbfa46f9",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5ad8cc752f3442d7a62aefe2ca79a299",
      "value": 100
     }
    },
    "e98cc65d8c9d463ea456675cfbfa46f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb4ba770895a4eb2b26912129aa86cef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
